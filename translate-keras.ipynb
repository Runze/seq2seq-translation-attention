{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras import Input, layers\n",
    "from keras.activations import softmax\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras import backend as K\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translation data\n",
    "# http://www.manythings.org/anki/\n",
    "with io.open(os.path.join(data_path, 'fra-eng/fra.txt'), encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "pairs = [l.split('\\t') for l in lines if l != '']\n",
    "pairs = [[re.sub(u\"\\u202f|\\u2009\", \" \", s) for s in p] for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154883, 154883)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = np.array(pairs)[:, 0], np.array(pairs)[:, 1]\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Go.', u'Va !'),\n",
       " (u'Run!', u'Cours !'),\n",
       " (u'Run!', u'Courez !'),\n",
       " (u'Fire!', u'Au feu !'),\n",
       " (u'Help!', u\"\\xc0 l'aide !\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(X, y)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "spacy_tokenizer = spacy.load('xx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154883, 154883)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(msg):\n",
    "    return [tok.text for tok in spacy_tokenizer.tokenizer(unicode(msg.lower()))]\n",
    "\n",
    "X = Parallel(n_jobs=num_cores)(delayed(tokenize)(msg) for msg in X)\n",
    "y = Parallel(n_jobs=num_cores)(delayed(tokenize)(msg) for msg in y)\n",
    "\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([u'go', u'.'], [u'va', u'!']),\n",
       " ([u'run', u'!'], [u'cours', u'!']),\n",
       " ([u'run', u'!'], [u'courez', u'!']),\n",
       " ([u'fire', u'!'], [u'au', u'feu', u'!']),\n",
       " ([u'help', u'!'], [u'\\xe0', u\"l'aide\", u'!'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(X, y)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154326"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For ease of training, only keep sentences shorter than 20 words\n",
    "X_len = [len(msg) for msg in X]\n",
    "y_len = [len(msg) for msg in y]\n",
    "\n",
    "min_len = 2\n",
    "max_len = 20\n",
    "\n",
    "X_to_keep_ix = np.where((np.array(X_len) >= min_len) & (np.array(X_len) <= max_len))[0]\n",
    "y_to_keep_ix = np.where((np.array(y_len) >= min_len) & (np.array(y_len) <= max_len))[0]\n",
    "\n",
    "to_keep_ix = np.intersect1d(X_to_keep_ix, y_to_keep_ix)\n",
    "len(to_keep_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154326, 154326)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)[to_keep_ix]\n",
    "y = np.array(y)[to_keep_ix]\n",
    "\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123460, 30866, 123460, 30866)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into training and validation sets\n",
    "X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "len(X_trn), len(X_val), len(y_trn), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929627, 982087)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mappers (using training data)\n",
    "X_toks_trn = list(itertools.chain(*X_trn))\n",
    "y_toks_trn = list(itertools.chain(*y_trn))\n",
    "\n",
    "len(X_toks_trn), len(y_toks_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNK = '_unk_'\n",
    "PAD = '_pad_'\n",
    "\n",
    "def create_mapper(toks, max_vocab=100000, min_freq=5, UNK=UNK, PAD=PAD):\n",
    "    \"\"\"Create mappers between tokens and numerical indices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    toks : A list containing all raw tokens (before deduping).\n",
    "\n",
    "    max_vocab : The maximum vocabulary size.\n",
    "\n",
    "    min_freq : The minimum frequency for a token to be included in the vocabulary.\n",
    "\n",
    "    UNK : Special token for unknown word (default to '_unk_').\n",
    "\n",
    "    PAD : Special token for paddings (default to '_pad_').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stoi : A dictionary that maps tokens to indices.\n",
    "\n",
    "    itos : A list that maps indices to tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    toks_freq = Counter(toks)\n",
    "    \n",
    "    itos = [s for s, c in toks_freq.most_common(max_vocab) if c > min_freq]\n",
    "    \n",
    "    if PAD:\n",
    "        if UNK:\n",
    "            itos.insert(0, UNK)\n",
    "            itos.insert(0, PAD)  # Note the index for UNK is 1 and the index for PAD is 0\n",
    "\n",
    "            stoi = defaultdict(lambda: 1, {v: k for k, v in enumerate(itos)})\n",
    "        else:\n",
    "            itos.insert(0, PAD)  # Note the index for PAD is 0\n",
    "            stoi = {v: k for k, v in enumerate(itos)}\n",
    "    else:\n",
    "        if UNK:\n",
    "            itos.insert(0, UNK)  # Note the index for UNK is 0\n",
    "            stoi = defaultdict(lambda: 0, {v: k for k, v in enumerate(itos)})\n",
    "        else:\n",
    "            stoi = {v: k for k, v in enumerate(itos)}\n",
    "    \n",
    "    return stoi, itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8488, 14519)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_stoi, X_itos = create_mapper(X_toks_trn, min_freq=1)\n",
    "y_stoi, y_itos = create_mapper(y_toks_trn, min_freq=1)\n",
    "\n",
    "len(X_itos), len(y_itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_pad_', '_unk_', u'.', u'i', u'you', u'to', u'the', u'?', u'a', u\"n't\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_pad_', '_unk_', u'.', u'je', u'de', u'-', u'?', u'pas', u'vous', u'que']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add GO\n",
    "GO = '_go_'\n",
    "\n",
    "X_stoi[GO] = len(X_stoi)\n",
    "X_itos.append(GO)\n",
    "\n",
    "y_stoi[GO] = len(y_stoi)\n",
    "y_itos.append(GO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode text features\n",
    "def encode_msg(toks, stoi, max_len, padding_pos='post', truncating='pre', padding_token=PAD):\n",
    "    # Index\n",
    "    toks_id = [[stoi[tok] for tok in msg] for msg in toks]\n",
    "    \n",
    "    # Pad\n",
    "    toks_id_pad = pad_sequences(toks_id, max_len, padding=padding_pos, truncating=truncating, value=stoi[padding_token])\n",
    "    \n",
    "    return toks_id_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123460, 20), (123460, 20), (30866, 20), (30866, 20))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ix_trn = encode_msg(X_trn, X_stoi, max_len)\n",
    "y_ix_trn = encode_msg(y_trn, y_stoi, max_len)\n",
    "X_ix_val = encode_msg(X_val, X_stoi, max_len)\n",
    "y_ix_val = encode_msg(y_val, y_stoi, max_len)\n",
    "\n",
    "X_ix_trn.shape, y_ix_trn.shape, X_ix_val.shape, y_ix_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([u'here', u'is', u'a', u'brief', u'description', u'.', u'_pad_',\n",
       "        u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_',\n",
       "        u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_',\n",
       "        u'_pad_'], dtype='<U17'),\n",
       " array([u'voici', u'une', u'br\\xe8ve', u'description', u'.', u'_pad_',\n",
       "        u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_',\n",
       "        u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_',\n",
       "        u'_pad_', u'_pad_'], dtype='<U19'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "np.array(X_itos)[X_ix_trn[0]], np.array(y_itos)[y_ix_trn[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([u'tom', u'said', u'my', u'plan', u'would', u\"n't\", u'work', u'.',\n",
       "        u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_',\n",
       "        u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_'],\n",
       "       dtype='<U17'),\n",
       " array([u'tom', u'a', u'dit', u'que', u'mon', u'plan', u'ne',\n",
       "        u'fonctionnera', u'pas', u'.', u'_pad_', u'_pad_', u'_pad_',\n",
       "        u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_', u'_pad_',\n",
       "        u'_pad_'], dtype='<U19'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_itos)[X_ix_val[0]], np.array(y_itos)[y_ix_val[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define hidden size\n",
    "hidden_size_enc = 128\n",
    "hidden_size_dec = 128\n",
    "\n",
    "# Define shared layers\n",
    "repeator_attn = layers.RepeatVector(max_len)\n",
    "concatenator_attn = layers.Concatenate(axis=-1)\n",
    "densor_attn = layers.Dense(1, activation='tanh')\n",
    "\n",
    "def softmax_axis_1(x):\n",
    "    return softmax(x, axis=1)\n",
    "activator_attn = layers.Activation(softmax_axis_1, name='attention_weights')\n",
    "\n",
    "dotor_attn = layers.Dot(axes=1, name='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define attention layer\n",
    "def one_step_attn(a, s_prev):\n",
    "    \"\"\"\n",
    "    One-step attention layer\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    a : All of the encoder hidden outputs, one at each timestep (None, timesteps, hidden_size_enc)\n",
    "    \n",
    "    s_prev : The decoder hidden output from the previous decoding timestamp (None, hidden_size_dec)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    context : Context vector (None, 1, hidden_size_dec)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Repeat `s_prev` to the same length of `a`\n",
    "    s_prev_rep = repeator_attn(s_prev)  # (None, timesteps, hidden_size_dec)\n",
    "    \n",
    "    # Concatenate with `a` (in the last axis)\n",
    "    concat = concatenator_attn([a, s_prev_rep])  # (None, timesteps, hidden_size_enc + hidden_size_dec)\n",
    "    \n",
    "    # Feed into a dense layer to compute weights\n",
    "    weights = densor_attn(concat)  # (None, timesteps, 1)\n",
    "    \n",
    "    # Normalize all the weights using a softmax (the normalization is applied in the timestep's axis)\n",
    "    weights_norm = activator_attn(weights)  # (None, timesteps, 1)\n",
    "    \n",
    "    # Use the normalized weights to compute the weighted-average encoder outputs (i.e., the context)\n",
    "    context = dotor_attn([weights_norm, a])  # (None, 1, hidden_size_dec)\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shared layers\n",
    "txt_embed_size = 256\n",
    "\n",
    "X_embed_layer = layers.Embedding(input_dim=len(X_itos), output_dim=txt_embed_size)\n",
    "lstm_pre_attn = layers.LSTM(hidden_size_enc, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input tensor\n",
    "X = Input(shape=(max_len, ), name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode\n",
    "def encode(X, X_embed_layer, lstm_pre_attn):\n",
    "    X_emb = X_embed_layer(X)\n",
    "    a_enc, s_enc, c_enc = lstm_pre_attn(X_emb)  # s and c becomes later the initial state of the decoder\n",
    "    return a_enc, s_enc, c_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shared layers\n",
    "y_embed_layer = layers.Embedding(input_dim=len(y_itos), output_dim=txt_embed_size)\n",
    "concatenator_post_attn = layers.Concatenate(axis=-1)\n",
    "lstm_post_attn = layers.LSTM(hidden_size_dec, return_state=True)\n",
    "densor_post_attn = layers.Dense(len(y_itos), activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decode only one timestep\n",
    "def one_step_decode(a_enc, s_dec_prev, c_dec_prev, d_in):\n",
    "    # Compute context vector using the attention layer\n",
    "    context = one_step_attn(a_enc, s_dec_prev)\n",
    "\n",
    "    # Concatenate with decoder input (one timestep only)\n",
    "    context_w_input = concatenator_post_attn([context, y_embed_layer(d_in)])\n",
    "\n",
    "    # Feed the context vector into the post-attention LSTM\n",
    "    _, s_dec, c_dec = lstm_post_attn(context_w_input, initial_state=[s_dec_prev, c_dec_prev])  # The first value (the output) and the second value (the hidden state) are the same\n",
    "\n",
    "    # Feed into a dense layer\n",
    "    d_out = densor_post_attn(s_dec)\n",
    "    \n",
    "    return s_dec, c_dec, d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Additional input tensor\n",
    "y = Input(shape=(max_len, ), name='y')  # Used for teacher-forcing\n",
    "d0 = Input(shape=(1, ), name='d0')  # Decoder starting token (\"_go_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode\n",
    "a_enc, s_enc, c_enc = encode(X, X_embed_layer, lstm_pre_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decode\n",
    "outputs = []\n",
    "d_in = d0\n",
    "s_dec = s_enc\n",
    "c_dec = c_enc\n",
    "\n",
    "for t in range(max_len):\n",
    "    s_dec, c_dec, d_out = one_step_decode(a_enc, s_dec, c_dec, d_in)\n",
    "    outputs.append(d_out)\n",
    "    \n",
    "    # Assign the next token as the next decoder input (teacher-forcing)\n",
    "    d_in = layers.Lambda(lambda x: x[:, t:t+1])(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 256)      2173184     X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 20, 128), (N 197120      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 20, 128)      0           lstm_1[0][1]                     \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[2][1]                     \n",
      "                                                                 lstm_2[3][1]                     \n",
      "                                                                 lstm_2[4][1]                     \n",
      "                                                                 lstm_2[5][1]                     \n",
      "                                                                 lstm_2[6][1]                     \n",
      "                                                                 lstm_2[7][1]                     \n",
      "                                                                 lstm_2[8][1]                     \n",
      "                                                                 lstm_2[9][1]                     \n",
      "                                                                 lstm_2[10][1]                    \n",
      "                                                                 lstm_2[11][1]                    \n",
      "                                                                 lstm_2[12][1]                    \n",
      "                                                                 lstm_2[13][1]                    \n",
      "                                                                 lstm_2[14][1]                    \n",
      "                                                                 lstm_2[15][1]                    \n",
      "                                                                 lstm_2[16][1]                    \n",
      "                                                                 lstm_2[17][1]                    \n",
      "                                                                 lstm_2[18][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 256)      0           lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[10][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[11][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[12][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[13][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[14][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[15][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[16][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[17][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[18][0]           \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 repeat_vector_1[19][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20, 1)        257         concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "                                                                 concatenate_1[10][0]             \n",
      "                                                                 concatenate_1[11][0]             \n",
      "                                                                 concatenate_1[12][0]             \n",
      "                                                                 concatenate_1[13][0]             \n",
      "                                                                 concatenate_1[14][0]             \n",
      "                                                                 concatenate_1[15][0]             \n",
      "                                                                 concatenate_1[16][0]             \n",
      "                                                                 concatenate_1[17][0]             \n",
      "                                                                 concatenate_1[18][0]             \n",
      "                                                                 concatenate_1[19][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 20, 1)        0           dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "                                                                 dense_1[10][0]                   \n",
      "                                                                 dense_1[11][0]                   \n",
      "                                                                 dense_1[12][0]                   \n",
      "                                                                 dense_1[13][0]                   \n",
      "                                                                 dense_1[14][0]                   \n",
      "                                                                 dense_1[15][0]                   \n",
      "                                                                 dense_1[16][0]                   \n",
      "                                                                 dense_1[17][0]                   \n",
      "                                                                 dense_1[18][0]                   \n",
      "                                                                 dense_1[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "d0 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context (Dot)                   (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[10][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[12][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[13][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[14][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[15][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[16][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[17][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[18][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 attention_weights[19][0]         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 256)       3717120     d0[0][0]                         \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 384)       0           context[0][0]                    \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 context[1][0]                    \n",
      "                                                                 embedding_2[1][0]                \n",
      "                                                                 context[2][0]                    \n",
      "                                                                 embedding_2[2][0]                \n",
      "                                                                 context[3][0]                    \n",
      "                                                                 embedding_2[3][0]                \n",
      "                                                                 context[4][0]                    \n",
      "                                                                 embedding_2[4][0]                \n",
      "                                                                 context[5][0]                    \n",
      "                                                                 embedding_2[5][0]                \n",
      "                                                                 context[6][0]                    \n",
      "                                                                 embedding_2[6][0]                \n",
      "                                                                 context[7][0]                    \n",
      "                                                                 embedding_2[7][0]                \n",
      "                                                                 context[8][0]                    \n",
      "                                                                 embedding_2[8][0]                \n",
      "                                                                 context[9][0]                    \n",
      "                                                                 embedding_2[9][0]                \n",
      "                                                                 context[10][0]                   \n",
      "                                                                 embedding_2[10][0]               \n",
      "                                                                 context[11][0]                   \n",
      "                                                                 embedding_2[11][0]               \n",
      "                                                                 context[12][0]                   \n",
      "                                                                 embedding_2[12][0]               \n",
      "                                                                 context[13][0]                   \n",
      "                                                                 embedding_2[13][0]               \n",
      "                                                                 context[14][0]                   \n",
      "                                                                 embedding_2[14][0]               \n",
      "                                                                 context[15][0]                   \n",
      "                                                                 embedding_2[15][0]               \n",
      "                                                                 context[16][0]                   \n",
      "                                                                 embedding_2[16][0]               \n",
      "                                                                 context[17][0]                   \n",
      "                                                                 embedding_2[17][0]               \n",
      "                                                                 context[18][0]                   \n",
      "                                                                 embedding_2[18][0]               \n",
      "                                                                 context[19][0]                   \n",
      "                                                                 embedding_2[19][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 128), (None, 262656      concatenate_2[0][0]              \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 concatenate_2[1][0]              \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 concatenate_2[2][0]              \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "                                                                 concatenate_2[3][0]              \n",
      "                                                                 lstm_2[2][1]                     \n",
      "                                                                 lstm_2[2][2]                     \n",
      "                                                                 concatenate_2[4][0]              \n",
      "                                                                 lstm_2[3][1]                     \n",
      "                                                                 lstm_2[3][2]                     \n",
      "                                                                 concatenate_2[5][0]              \n",
      "                                                                 lstm_2[4][1]                     \n",
      "                                                                 lstm_2[4][2]                     \n",
      "                                                                 concatenate_2[6][0]              \n",
      "                                                                 lstm_2[5][1]                     \n",
      "                                                                 lstm_2[5][2]                     \n",
      "                                                                 concatenate_2[7][0]              \n",
      "                                                                 lstm_2[6][1]                     \n",
      "                                                                 lstm_2[6][2]                     \n",
      "                                                                 concatenate_2[8][0]              \n",
      "                                                                 lstm_2[7][1]                     \n",
      "                                                                 lstm_2[7][2]                     \n",
      "                                                                 concatenate_2[9][0]              \n",
      "                                                                 lstm_2[8][1]                     \n",
      "                                                                 lstm_2[8][2]                     \n",
      "                                                                 concatenate_2[10][0]             \n",
      "                                                                 lstm_2[9][1]                     \n",
      "                                                                 lstm_2[9][2]                     \n",
      "                                                                 concatenate_2[11][0]             \n",
      "                                                                 lstm_2[10][1]                    \n",
      "                                                                 lstm_2[10][2]                    \n",
      "                                                                 concatenate_2[12][0]             \n",
      "                                                                 lstm_2[11][1]                    \n",
      "                                                                 lstm_2[11][2]                    \n",
      "                                                                 concatenate_2[13][0]             \n",
      "                                                                 lstm_2[12][1]                    \n",
      "                                                                 lstm_2[12][2]                    \n",
      "                                                                 concatenate_2[14][0]             \n",
      "                                                                 lstm_2[13][1]                    \n",
      "                                                                 lstm_2[13][2]                    \n",
      "                                                                 concatenate_2[15][0]             \n",
      "                                                                 lstm_2[14][1]                    \n",
      "                                                                 lstm_2[14][2]                    \n",
      "                                                                 concatenate_2[16][0]             \n",
      "                                                                 lstm_2[15][1]                    \n",
      "                                                                 lstm_2[15][2]                    \n",
      "                                                                 concatenate_2[17][0]             \n",
      "                                                                 lstm_2[16][1]                    \n",
      "                                                                 lstm_2[16][2]                    \n",
      "                                                                 concatenate_2[18][0]             \n",
      "                                                                 lstm_2[17][1]                    \n",
      "                                                                 lstm_2[17][2]                    \n",
      "                                                                 concatenate_2[19][0]             \n",
      "                                                                 lstm_2[18][1]                    \n",
      "                                                                 lstm_2[18][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "y (InputLayer)                  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1)            0           y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14520)        1873080     lstm_2[0][1]                     \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[2][1]                     \n",
      "                                                                 lstm_2[3][1]                     \n",
      "                                                                 lstm_2[4][1]                     \n",
      "                                                                 lstm_2[5][1]                     \n",
      "                                                                 lstm_2[6][1]                     \n",
      "                                                                 lstm_2[7][1]                     \n",
      "                                                                 lstm_2[8][1]                     \n",
      "                                                                 lstm_2[9][1]                     \n",
      "                                                                 lstm_2[10][1]                    \n",
      "                                                                 lstm_2[11][1]                    \n",
      "                                                                 lstm_2[12][1]                    \n",
      "                                                                 lstm_2[13][1]                    \n",
      "                                                                 lstm_2[14][1]                    \n",
      "                                                                 lstm_2[15][1]                    \n",
      "                                                                 lstm_2[16][1]                    \n",
      "                                                                 lstm_2[17][1]                    \n",
      "                                                                 lstm_2[18][1]                    \n",
      "                                                                 lstm_2[19][1]                    \n",
      "==================================================================================================\n",
      "Total params: 8,223,417\n",
      "Trainable params: 8,223,417\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Put together\n",
    "model = Model(inputs=[X, y, d0], outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize decoder input\n",
    "d0_trn = np.array([y_stoi[GO]] * len(X_ix_trn)).reshape(-1, 1)\n",
    "d0_val = np.array([y_stoi[GO]] * len(X_ix_val)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add callbacks\n",
    "callbacks = []\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
    "callbacks.append(reduce_lr)\n",
    "\n",
    "stopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "callbacks.append(stopper)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=os.path.join(model_path, 'translate-keras.h5'), monitor='val_loss', save_best_only=True, verbose=1)\n",
    "callbacks.append(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, (123460, 1), (30866, 1))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape outputs in order to use `sparse_categorical_crossentropy`\n",
    "y_ix_trn_rs = [y_ix_trn[:, i:(i+1)] for i in range(y_ix_trn.shape[1])]\n",
    "y_ix_val_rs = [y_ix_val[:, i:(i+1)] for i in range(y_ix_val.shape[1])]\n",
    "\n",
    "len(y_ix_trn_rs), len(y_ix_val_rs), y_ix_trn_rs[0].shape, y_ix_val_rs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "hist = model.fit(\n",
    "    x=[X_ix_trn, y_ix_trn, d0_trn],\n",
    "    y=y_ix_trn_rs,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    validation_data=([X_ix_val, y_ix_val, d0_val], y_ix_val_rs),\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_losses_and_metrics(model_hist):\n",
    "    \"\"\"Plot losses at the end of the training\"\"\"\n",
    "\n",
    "    loss = pd.DataFrame(zip(model_hist.history['loss'], model_hist.history['val_loss']), columns=['loss', 'val_loss'])\n",
    "\n",
    "    # Find the epoch with the smallest loss\n",
    "    min_loss_ix = np.array(model_hist.history['val_loss']).argmin()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    loss.plot(ax=ax)\n",
    "    ax.axvline(x=min_loss_ix, color='black', ls='--')\n",
    "    plt.show()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt4AAAIFCAYAAADlbfqzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKQAFLxFRERERApAwVtEREREpAD+H0cw5854O/FdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97c1ec2e10>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 258,
       "width": 367
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.050375</td>\n",
       "      <td>31.249202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.237904</td>\n",
       "      <td>26.307415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.413294</td>\n",
       "      <td>23.419551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.258238</td>\n",
       "      <td>22.442736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.986619</td>\n",
       "      <td>21.693549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.767221</td>\n",
       "      <td>20.638794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.211026</td>\n",
       "      <td>20.822668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.867479</td>\n",
       "      <td>20.155217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.273522</td>\n",
       "      <td>19.954648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.745829</td>\n",
       "      <td>19.657878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.387931</td>\n",
       "      <td>19.576570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.209768</td>\n",
       "      <td>19.487418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.022059</td>\n",
       "      <td>19.415803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.634194</td>\n",
       "      <td>19.464583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.315166</td>\n",
       "      <td>19.295580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.055489</td>\n",
       "      <td>19.337658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.879872</td>\n",
       "      <td>19.293444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.783678</td>\n",
       "      <td>19.351260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.703312</td>\n",
       "      <td>19.377505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15.565810</td>\n",
       "      <td>19.364402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss   val_loss\n",
       "0   38.050375  31.249202\n",
       "1   28.237904  26.307415\n",
       "2   24.413294  23.419551\n",
       "3   22.258238  22.442736\n",
       "4   20.986619  21.693549\n",
       "5   19.767221  20.638794\n",
       "6   19.211026  20.822668\n",
       "7   18.867479  20.155217\n",
       "8   18.273522  19.954648\n",
       "9   17.745829  19.657878\n",
       "10  17.387931  19.576570\n",
       "11  17.209768  19.487418\n",
       "12  17.022059  19.415803\n",
       "13  16.634194  19.464583\n",
       "14  16.315166  19.295580\n",
       "15  16.055489  19.337658\n",
       "16  15.879872  19.293444\n",
       "17  15.783678  19.351260\n",
       "18  15.703312  19.377505\n",
       "19  15.565810  19.364402"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_losses_and_metrics(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 20, 256)           2173184   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 20, 128), (None,  197120    \n",
      "=================================================================\n",
      "Total params: 2,370,304\n",
      "Trainable params: 2,370,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract encoder\n",
    "encoder = Model(X, encode(X, X_embed_layer, lstm_pre_attn))\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "s_dec_prev (InputLayer)         (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a_enc (InputLayer)              (None, 20, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 20, 128)      0           s_dec_prev[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 256)      0           a_enc[0][0]                      \n",
      "                                                                 repeat_vector_1[20][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20, 1)        257         concatenate_1[20][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 20, 1)        0           dense_1[20][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "d_in (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context (Dot)                   (None, 1, 128)       0           attention_weights[20][0]         \n",
      "                                                                 a_enc[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 256)       3717120     d_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 384)       0           context[20][0]                   \n",
      "                                                                 embedding_2[20][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c_dec_prev (InputLayer)         (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 128), (None, 262656      concatenate_2[20][0]             \n",
      "                                                                 s_dec_prev[0][0]                 \n",
      "                                                                 c_dec_prev[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14520)        1873080     lstm_2[20][1]                    \n",
      "==================================================================================================\n",
      "Total params: 5,853,113\n",
      "Trainable params: 5,853,113\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract decoder\n",
    "a_enc = Input(shape=(max_len, hidden_size_enc), name='a_enc')\n",
    "s_dec_prev = Input(shape=(hidden_size_dec, ), name='s_dec_prev')\n",
    "c_dec_prev = Input(shape=(hidden_size_dec, ), name='c_dec_prev')\n",
    "d_in = Input(shape=(1, ), name='d_in')\n",
    "\n",
    "decoder = Model([a_enc, s_dec_prev, c_dec_prev, d_in], one_step_decode(a_enc, s_dec_prev, c_dec_prev, d_in))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seqs):\n",
    "    # Generate encoder output\n",
    "    a_enc_pred, s_enc_pred, c_enc_pred = encoder.predict(input_seqs)\n",
    "\n",
    "    # Generate decoder output, one timestep at a time\n",
    "    outputs_pred = []\n",
    "    d_in_pred = np.array([y_stoi[GO]] * len(input_seqs)).reshape(-1, 1)\n",
    "    s_dec_pred = s_enc_pred\n",
    "    c_dec_pred = c_enc_pred\n",
    "\n",
    "    for t in range(max_len):\n",
    "        s_dec_pred, c_dec_pred, d_out_pred = decoder.predict([a_enc_pred, s_dec_pred, c_dec_pred, d_in_pred])\n",
    "\n",
    "        # Derive the predicted token\n",
    "        d_out_pred = d_out_pred.argmax(axis=-1)\n",
    "\n",
    "        outputs_pred.append(d_out_pred)\n",
    "\n",
    "        # Assign the predicted token as the next decoder input\n",
    "        d_in_pred = d_out_pred\n",
    "\n",
    "    # Convert output index into tokens\n",
    "    output_seqs = np.array(y_itos)[np.array(outputs_pred).transpose()]\n",
    "    \n",
    "    # Clean up and output\n",
    "    output_seqs = [detok(toks) for toks in output_seqs]\n",
    "    \n",
    "    return output_seqs\n",
    "\n",
    "# Convert to strings and clean up\n",
    "detokenizer = Detok()\n",
    "\n",
    "def detok(toks):\n",
    "    # Cut before the first padding (if any)\n",
    "    toks = list(toks)\n",
    "    if PAD in toks:\n",
    "        first_pad = toks.index(PAD)\n",
    "        toks = toks[:first_pad]\n",
    "    \n",
    "    return detokenizer.detokenize(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30866"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test inference with validation data\n",
    "y_val_pred = decode_sequence(X_ix_val)\n",
    "len(y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Input:\t\ttom said my plan wouldn't work.\n",
      "Predicted:\ttom a dit que son travail ne m'a pas pu se.\n",
      "True:\t\ttom a dit que mon plan ne fonctionnera pas.\n",
      "1\n",
      "Input:\t\ta watered down compromise resolution is better than none at all.\n",
      "Predicted:\tun _unk_ _unk_ est plus petit que _unk_ tous les sera.\n",
      "True:\t\tune rsolution sur un compromis restreint est prfrable  rien du tout.\n",
      "2\n",
      "Input:\t\tcould i get one more beer, please?\n",
      "Predicted:\tpourrais - je avoir une plus de bire, s'il vous plat?\n",
      "True:\t\tpourrais - je avoir une bire supplmentaire, je vous prie?\n",
      "3\n",
      "Input:\t\ti want to ask you one simple question.\n",
      "Predicted:\tje veux vous poser une question une pas enfant!\n",
      "True:\t\tje veux te poser une simple question.\n",
      "4\n",
      "Input:\t\ti can't stand to see animals be teased.\n",
      "Predicted:\tje ne peux voir pas de _unk_ des _unk_ de voir des _unk_.\n",
      "True:\t\tje ne supporte pas de voir des animaux tre taquins.\n"
     ]
    }
   ],
   "source": [
    "# Print out a few results\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    print('Input:\\t\\t' + detok(X_val[i]))\n",
    "    print('Predicted:\\t' + y_val_pred[i])\n",
    "    print('True:\\t\\t' + detok(y_val[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test loading models in a new session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = load_model(os.path.join(model_path, 'translate-keras.h5'), custom_objects={'softmax_axis_1': softmax_axis_1, 't': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 20, 256)           2173184   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 20, 128), (None,  197120    \n",
      "=================================================================\n",
      "Total params: 2,370,304\n",
      "Trainable params: 2,370,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract encoder\n",
    "X = Input(shape=(max_len, ), name='X')\n",
    "encoder = Model(X, encode(X, model.get_layer('embedding_1'), model.get_layer('lstm_1')))\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "s_dec_prev (InputLayer)         (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "a_enc (InputLayer)              (None, 20, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 20, 128)      0           s_dec_prev[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 256)      0           a_enc[0][0]                      \n",
      "                                                                 repeat_vector_1[20][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20, 1)        257         concatenate_1[20][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 20, 1)        0           dense_1[20][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "d_in (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context (Dot)                   (None, 1, 128)       0           attention_weights[20][0]         \n",
      "                                                                 a_enc[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 256)       3717120     d_in[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 384)       0           context[20][0]                   \n",
      "                                                                 embedding_2[20][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c_dec_prev (InputLayer)         (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 128), (None, 262656      concatenate_2[20][0]             \n",
      "                                                                 s_dec_prev[0][0]                 \n",
      "                                                                 c_dec_prev[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14520)        1873080     lstm_2[20][1]                    \n",
      "==================================================================================================\n",
      "Total params: 5,853,113\n",
      "Trainable params: 5,853,113\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract decoder\n",
    "hidden_size_enc = 128\n",
    "hidden_size_dec = 128\n",
    "a_enc = Input(shape=(max_len, hidden_size_enc), name='a_enc')\n",
    "s_dec_prev = Input(shape=(hidden_size_dec, ), name='s_dec_prev')\n",
    "c_dec_prev = Input(shape=(hidden_size_dec, ), name='c_dec_prev')\n",
    "d_in = Input(shape=(1, ), name='d_in')\n",
    "\n",
    "repeator_attn = model.get_layer('repeat_vector_1')\n",
    "concatenator_attn = model.get_layer('concatenate_1')\n",
    "densor_attn = model.get_layer('dense_1')\n",
    "activator_attn = model.get_layer('attention_weights')\n",
    "dotor_attn = model.get_layer('context')\n",
    "\n",
    "y_embed_layer = model.get_layer('embedding_2')\n",
    "concatenator_post_attn = model.get_layer('concatenate_2')\n",
    "lstm_post_attn = model.get_layer('lstm_2')\n",
    "densor_post_attn = model.get_layer('dense_2')\n",
    "\n",
    "decoder = Model([a_enc, s_dec_prev, c_dec_prev, d_in], one_step_decode(a_enc, s_dec_prev, c_dec_prev, d_in))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test inference with validation data\n",
    "y_val_pred_head = decode_sequence(X_ix_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tom a dit que son plan n'tait pas partie.\n",
      "un _unk_ _unk_ est _unk_ de ne plus que tous les _unk_.\n",
      "puis - je avoir une bire, s'il vous plat?\n",
      "je veux vous poser une question une qui te sens.\n",
      "je ne peux pas voir avec les femmes qui se sont _unk_.\n"
     ]
    }
   ],
   "source": [
    "for p in y_val_pred_head:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (General DS)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
