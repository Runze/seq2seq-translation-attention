{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import model_selection\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#loading-data-files\n",
    "lines = open('data/tatoeba/eng-fra.txt').read().strip().split('\\n')\n",
    "pairs = [l.split('\\t') for l in lines]\n",
    "pairs = [[text_to_word_sequence(re.sub(r\"\\u202f|\\u2009\", r\"\", s)) for s in p] for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [p[0] for p in pairs]\n",
    "y = [p[1] for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9962824457826004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For ease of training, only keep sentences shorter than 20 words\n",
    "X_len = [len(sentence) for sentence in X]\n",
    "y_len = [len(sentence) for sentence in y]\n",
    "\n",
    "min_len = 2\n",
    "max_len = 20\n",
    "\n",
    "X_to_keep_ix = np.where((np.array(X_len) >= min_len) & (np.array(X_len) <= max_len))\n",
    "y_to_keep_ix = np.where((np.array(y_len) >= min_len) & (np.array(y_len) <= max_len))\n",
    "\n",
    "to_keep_ix = list(set(np.intersect1d(X_to_keep_ix, y_to_keep_ix)))\n",
    "len(to_keep_ix) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135337, 135337)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small = np.array(X)[to_keep_ix]\n",
    "y_small = np.array(y)[to_keep_ix]\n",
    "\n",
    "len(X_small), len(y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20, 2, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "X_len = [len(sentence) for sentence in X_small]\n",
    "y_len = [len(sentence) for sentence in y_small]\n",
    "\n",
    "min(X_len), max(X_len), min(y_len), max(y_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([list(['i', 'see']), list(['i', 'won']), list(['i', 'won']),\n",
       "        list(['oh', 'no']), list(['get', 'up'])], dtype=object),\n",
       " array([list(['je', 'comprends']), list([\"j'ai\", 'gagné']),\n",
       "        list(['je', \"l'ai\", 'emporté']), list(['oh', 'non']),\n",
       "        list(['lève', 'toi'])], dtype=object))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small[:5], y_small[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word-to-index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_word_to_id_mapping(data, max_vocab_size = 20000):\n",
    "    counter = collections.Counter(np.hstack(data))\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    # Pick the most common ones\n",
    "    count_pairs = count_pairs[:max_vocab_size]\n",
    "\n",
    "    # Add 'ZERO', 'GO', and 'UNK'\n",
    "    # It is important to add 'ZERO' in the beginning\n",
    "    # to make sure zero padding does not interfere with existing words\n",
    "    count_pairs.insert(0, ('GO', 0))\n",
    "    count_pairs.insert(0, ('ZERO', 0))\n",
    "    count_pairs.append(('UNK', 0))\n",
    "\n",
    "    # Create mapping for both directions\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    id_to_word = dict(zip(range(len(words)), words))\n",
    "    \n",
    "    # Map words to indexes\n",
    "    data_id = [[word_to_id[word] if word in word_to_id else word_to_id['UNK'] for word in sentence] for sentence in data]\n",
    "    \n",
    "    return word_to_id, id_to_word, data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_word_to_id, X_id_to_word, X_id = create_word_to_id_mapping(X_small)\n",
    "y_word_to_id, y_id_to_word, y_id = create_word_to_id_mapping(y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135337 135337 13512 20003\n"
     ]
    }
   ],
   "source": [
    "print(len(X_id), len(y_id), len(X_word_to_id), len(y_word_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_vocab_size, y_vocab_size = len(X_word_to_id), len(y_word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i see\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([X_id_to_word[i] for i in X_id[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je comprends\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([y_id_to_word[i] for i in y_id[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad zeros to make sentences equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_id_padded = pad_sequences(X_id, maxlen=max_len, padding='post')\n",
    "y_id_padded = pad_sequences(y_id, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 20, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "X_len = [len(sentence) for sentence in X_id_padded]\n",
    "y_len = [len(sentence) for sentence in y_id_padded]\n",
    "\n",
    "min(X_len), max(X_len), min(y_len), max(y_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leverage pre-trained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English word vectors downloaded from https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code stolen from https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "embeddings_index_en = {}\n",
    "f = open('data/glove.6B/glove.6B.200d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index_en[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French word vectors downloaded from http://fauconnier.github.io/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index_fr = word2vec.KeyedVectors.load_word2vec_format(\n",
    "    'data/frWac_non_lem_no_postag_no_phrase_200_skip_cut100.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map words to pre-trained embeddings\n",
    "def map_word_to_pretrained_embedding(embeddings_index, embedding_size, word_to_id):\n",
    "    vocab_size = len(word_to_id)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_size))\n",
    "    \n",
    "    # Keep a running count of matched words\n",
    "    found = 0\n",
    "    \n",
    "    for word, i in word_to_id.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_vector = embeddings_index[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            found += 1\n",
    "        else:\n",
    "            # Words not found in embedding index will be randomly initialized\n",
    "            embedding_matrix[i] = np.random.normal(size=(embedding_size, ))\n",
    "\n",
    "    return embedding_matrix, found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13512, 200), 0.9655121373593842)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embeddings, X_found = map_word_to_pretrained_embedding(embeddings_index_en, 200, X_word_to_id)\n",
    "X_embeddings.shape, X_found / X_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20003, 200), 0.83257511373294)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_embeddings, y_found = map_word_to_pretrained_embedding(embeddings_index_fr, 200, y_word_to_id)\n",
    "y_embeddings.shape, y_found / y_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'data/tatoeba/training_data.pickle'\n",
    "\n",
    "f = open(pickle_file, 'wb')\n",
    "save = {\n",
    "    'X_small': X_small,\n",
    "    'y_small': y_small,\n",
    "    'X_word_to_id': X_word_to_id,\n",
    "    'X_id_to_word': X_id_to_word,\n",
    "    'y_word_to_id': y_word_to_id,\n",
    "    'y_id_to_word': y_id_to_word,\n",
    "    'X_id_padded': X_id_padded,\n",
    "    'y_id_padded': y_id_padded,\n",
    "    'X_embeddings': X_embeddings,\n",
    "    'y_embeddings': y_embeddings\n",
    "}\n",
    "\n",
    "pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data that was processed last time\n",
    "pickle_file = 'data/tatoeba/training_data.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    \n",
    "    X_small = save['X_small']\n",
    "    y_small = save['y_small']\n",
    "    X_word_to_id = save['X_word_to_id']\n",
    "    X_id_to_word = save['X_id_to_word']\n",
    "    y_word_to_id = save['y_word_to_id']\n",
    "    y_id_to_word = save['y_id_to_word']\n",
    "    X_id_padded = save['X_id_padded']\n",
    "    y_id_padded = save['y_id_padded']\n",
    "    X_embeddings = save['X_embeddings']\n",
    "    y_embeddings = save['y_embeddings']\n",
    "    \n",
    "    del save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51054, 51054)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing purposes, only include sentences that start with \"I\", \"you\", \"he\", \"she\", and \"we\"\n",
    "starts_with_subject_pronouns = np.array([\n",
    "    s[0] in [\n",
    "        X_word_to_id[\"i\"], X_word_to_id[\"you\"], X_word_to_id[\"he\"],\n",
    "        X_word_to_id[\"she\"], X_word_to_id[\"we\"]\n",
    "    ] for s in X_id_padded\n",
    "])\n",
    "starts_with_subject_pronouns = np.where(starts_with_subject_pronouns)[0]\n",
    "\n",
    "X_id_padded, y_id_padded = X_id_padded[starts_with_subject_pronouns], y_id_padded[starts_with_subject_pronouns]\n",
    "len(X_id_padded), len(y_id_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_id_padded_train, X_id_padded_test, y_id_padded_train, y_id_padded_test = model_selection.train_test_split(\n",
    "    X_id_padded, y_id_padded, test_size=0.1, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(45948, 20), (5106, 20), (45948, 20), (5106, 20)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.shape for e in (X_id_padded_train, X_id_padded_test, y_id_padded_train, y_id_padded_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we want peace in the world ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([X_id_to_word[i] for i in X_id_padded_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nous désirons la paix dans le monde ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO ZERO\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([y_id_to_word[i] for i in y_id_padded_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13512, 200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert pre-trained embeddings to a tensor\n",
    "X_embeddings = torch.FloatTensor(X_embeddings)\n",
    "y_embeddings = torch.FloatTensor(y_embeddings)\n",
    "\n",
    "if use_cuda:\n",
    "    X_embeddings = X_embeddings.cuda()\n",
    "    y_embeddings = y_embeddings.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a embedding layer initialized with pre-trained embedding matrix\n",
    "def create_embedding(init_embeddings, trainable=True):\n",
    "    vocab_size, embedding_size = init_embeddings.size()\n",
    "    embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "    embedding.load_state_dict({'weight': init_embeddings})\n",
    "    \n",
    "    if use_cuda:\n",
    "        embedding = embedding.cuda()\n",
    "    \n",
    "    if not trainable:\n",
    "        for param in embeddings.parameters(): \n",
    "            param.requires_grad = False\n",
    "    \n",
    "    return embedding, vocab_size, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(13512, 200), 13512, 200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dimensions\n",
    "create_embedding(X_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create encoder RNN using LSTM\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, init_embeddings, hidden_size, n_layers=2):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.embedding, vocab_size, embedding_size = create_embedding(init_embeddings)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, batch_first=True)\n",
    "        if use_cuda:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "    \n",
    "    def forward(self, input, states):\n",
    "        output, states = self.lstm(self.embedding(input), states)\n",
    "        return output, states\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        init_hidden_state = Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "        init_cell_state = Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "        \n",
    "        if use_cuda:\n",
    "            return (init_hidden_state.cuda(), init_cell_state.cuda())\n",
    "        else:\n",
    "            return (init_hidden_state, init_cell_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly initialized weight matrices\n",
    "def arr(*size):\n",
    "    return torch.randn(size) / math.sqrt(size[0])\n",
    "\n",
    "def param(*size):\n",
    "    if use_cuda:\n",
    "        return nn.Parameter(arr(*size)).cuda()\n",
    "    else:\n",
    "        return nn.Parameter(arr(*size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy style dot operation to multiply a 3D matrix with a 2D one\n",
    "# Based on https://discuss.pytorch.org/t/how-can-i-compute-3d-tensor-2d-tensor-multiplication/639/9\n",
    "def dot(X, Y):\n",
    "    return torch.bmm(X, Y.unsqueeze(0).expand(X.size(0), *Y.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$u^t_i = v^T tanh(W_1′ h_i + W_2′ d_t)$$\n",
    "$$a^t_i = softmax(u^t_i)$$\n",
    "$$d_t' = \\sum_i^{T_A} a^t_i h_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, init_embeddings, hidden_size, n_layers=2):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.embedding, vocab_size, embedding_size = create_embedding(init_embeddings)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Define weights and intercepts used in paper 1412.7449\n",
    "        # to construct the allignment matrix: u^t_i = v^T tanh(W_1′ h_i + W_2′ d_t)\n",
    "        self.W1 = param(hidden_size, hidden_size)\n",
    "        self.W2 = param(hidden_size, hidden_size)\n",
    "        self.b = param(hidden_size)\n",
    "        self.v = param(hidden_size)\n",
    "        \n",
    "        # Linear layer to reshape hidden state, concatenated with either the previous true label or prediction,\n",
    "        # back to the shape of hidden state\n",
    "        # As the new input to LSTM\n",
    "        self.new_input = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
    "        \n",
    "        # LSTM layers using the new concatenated hidden state as the input\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        # Linear layer to reshape data to the shape of output vocabulary\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        if use_cuda:\n",
    "            self.new_input = self.new_input.cuda()\n",
    "            self.lstm = self.lstm.cuda()\n",
    "            self.out = self.out.cuda()\n",
    "    \n",
    "    def forward(self, input, states, encoder_outputs):\n",
    "        # u^t_i = v^T tanh(W_1′ h_i + W_2′ d_t)\n",
    "        W1h = dot(encoder_outputs, self.W1)            # (batch_size, seq_length, hidden_size)\n",
    "        hidden_state = states[0]                       # (n_layers, batch_size, hidden_size)\n",
    "        W2d = hidden_state[-1].mm(self.W2)             # (batch_size, hidden_size)\n",
    "        W1h_W2d = W1h + W2d.unsqueeze(1) + self.b      # (batch_size, seq_length, hidden_size)\n",
    "        tahn_W1h_W2d = F.tanh(W1h_W2d)                 # (batch_size, seq_length, hidden_size)\n",
    "        u = (tahn_W1h_W2d * self.v).sum(2)             # (batch_size, seq_length)\n",
    "        \n",
    "        # a^t_i = softmax(u^t_i)\n",
    "        a = F.softmax(u)                               # (batch_size, seq_length)\n",
    "        \n",
    "        # d_t' = \\sum_i^{T_A} a^t_i h_i\n",
    "        encoder_outputs_weighted_sum = (a.unsqueeze(2) * encoder_outputs).sum(1)\n",
    "                                                       # (batch_size, hidden_size)\n",
    "        \n",
    "        # Concatenate with decoder input,\n",
    "        # which is either the previous true label or prediction\n",
    "        concat_input = torch.cat((encoder_outputs_weighted_sum, self.embedding(input)), 1)\n",
    "                                                       # (batch_size, hidden_size + embedding_size)\n",
    "        \n",
    "        # Reshape the concatenated input back to the shape of hidden state\n",
    "        reshaped_input = self.new_input(concat_input)  # (batch_size, hidden_size)\n",
    "        \n",
    "        # Feed the new input into the LSTM layer\n",
    "        output, states = self.lstm(reshaped_input.unsqueeze(0), states)\n",
    "        output = output.squeeze(0)                     # (batch_size, hidden_size)\n",
    "        \n",
    "        # Finally, feed to the output layer\n",
    "        output = self.out(output)                      # (batch_size, vocab_size)\n",
    "        output = F.log_softmax(output)                 # (batch_size, vocab_size)\n",
    "        \n",
    "        return output, states, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(X, y, i, batch_size):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    return X[start:end], y[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "i = 0\n",
    "\n",
    "X_input, y_input = get_batch(X_id_padded_train, y_id_padded_train, i, batch_size)\n",
    "X_input, y_input = Variable(torch.from_numpy(X_input).long()), Variable(torch.from_numpy(y_input).long())\n",
    "X_seq_length, y_seq_length = X_input.size()[1], y_input.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 10]), torch.Size([2, 5, 10]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 10\n",
    "encoder = EncoderRNN(X_embeddings, hidden_size)\n",
    "\n",
    "encoder_states = encoder.initHidden(batch_size)\n",
    "encoder_states[0].size(), encoder_states[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 20, 10]), torch.Size([2, 5, 10]), torch.Size([2, 5, 10]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs, encoder_states = encoder(X_input, encoder_states)\n",
    "encoder_outputs.size(), encoder_states[0].size(), encoder_states[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(y_embeddings, hidden_size)\n",
    "\n",
    "decoder_states = encoder_states\n",
    "decoder_input = Variable(torch.LongTensor([X_word_to_id['GO']] * batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_attentions = np.zeros((batch_size, y_seq_length, y_seq_length))\n",
    "\n",
    "for i in range(y_seq_length):\n",
    "    decoder_output, decoder_states, decoder_attention = decoder(decoder_input, decoder_states, encoder_outputs)\n",
    "    decoder_input = y_input[:, i]\n",
    "    decoder_attentions[:, i, :] = decoder_attention.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 20003]),\n",
       " torch.Size([2, 5, 10]),\n",
       " torch.Size([2, 5, 10]),\n",
       " torch.Size([5, 20]),\n",
       " (5, 20, 20))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.size(), decoder_states[0].size(), decoder_states[1].size(), decoder_attention.size(), decoder_attentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_input, y_input, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, teacher_forcing_prob=0.5):\n",
    "    # Initialize variables\n",
    "    batch_size, X_seq_length = X_input.size()\n",
    "    y_seq_length = y_input.size()[1]\n",
    "    \n",
    "    encoder_states = encoder.initHidden(batch_size)\n",
    "    decoder_input = Variable(torch.LongTensor([X_word_to_id['GO']] * batch_size))\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    # Encode\n",
    "    encoder_outputs, encoder_states = encoder(X_input, encoder_states)\n",
    "    decoder_states = encoder_states\n",
    "\n",
    "    # Decode\n",
    "    if np.random.random() <= teacher_forcing_prob:\n",
    "        # Teacher forcing: use the true label as the next decoder input\n",
    "        for i in range(y_seq_length):\n",
    "            decoder_output, decoder_states, decoder_attention = decoder(decoder_input, decoder_states, encoder_outputs)\n",
    "            loss += criterion(decoder_output, y_input[:, i])\n",
    "            decoder_input = y_input[:, i]\n",
    "    else:\n",
    "        # Otherwise, use the previous prediction\n",
    "        for i in range(y_seq_length):\n",
    "            decoder_output, decoder_states, decoder_attention = decoder(decoder_input, decoder_states, encoder_outputs)\n",
    "            loss += criterion(decoder_output, y_input[:, i])\n",
    "            \n",
    "            # Generate prediction\n",
    "            top_value, top_index = decoder_output.data.topk(1)\n",
    "            decoder_input = Variable(top_index.squeeze(1))\n",
    "            if use_cuda:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / y_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train an epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(X, y, batch_size, encoder, decoder, lr=0.01, teacher_forcing_prob=0.5):\n",
    "    total_loss = 0\n",
    "    \n",
    "    encoder_optimizer = optim.RMSprop(encoder.parameters(), lr=lr)\n",
    "    decoder_optimizer = optim.RMSprop(decoder.parameters(), lr=lr)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    if use_cuda:\n",
    "        criterion = criterion.cuda()\n",
    "    \n",
    "    # loop over batches\n",
    "    epoch_size = len(X) // batch_size\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        X_batch, y_batch = get_batch(X, y, i, batch_size)\n",
    "        \n",
    "        X_batch = Variable(torch.from_numpy(X_batch).long())\n",
    "        y_batch = Variable(torch.from_numpy(y_batch).long())\n",
    "        \n",
    "        if use_cuda:\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        loss = train(X_batch, y_batch, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion, teacher_forcing_prob)\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    return total_loss / epoch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(X_input, encoder, decoder, max_len):\n",
    "    # Initialize variables\n",
    "    batch_size, X_seq_length = X_input.size()\n",
    "    \n",
    "    encoder_states = encoder.initHidden(batch_size)\n",
    "    decoder_input = Variable(torch.LongTensor([X_word_to_id['GO']] * batch_size))\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    # Encode\n",
    "    encoder_outputs, encoder_states = encoder(X_input, encoder_states)\n",
    "    decoder_states = encoder_states\n",
    "\n",
    "    # Decode\n",
    "    decoded_words = np.zeros((batch_size, max_len))\n",
    "    decoder_attentions = np.zeros((batch_size, max_len, max_len))\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        decoder_output, decoder_states, decoder_attention = decoder(decoder_input, decoder_states, encoder_outputs)\n",
    "        \n",
    "        # Generate prediction\n",
    "        top_value, top_index = decoder_output.data.topk(1)\n",
    "        decoded_words[:, i] = top_index.squeeze(1).cpu().numpy()\n",
    "        decoder_attentions[:, i, :] = decoder_attention.data.cpu().numpy()\n",
    "        \n",
    "        # Use the prediction as the next decoder input\n",
    "        decoder_input = Variable(top_index.squeeze(1))\n",
    "        if use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words, decoder_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "max_len = len(X_id_padded[0])\n",
    "batch_size = 100\n",
    "hidden_size = 200\n",
    "learning_rate = 0.005\n",
    "teacher_forcing_prob = 0.5\n",
    "\n",
    "encoder = EncoderRNN(X_embeddings, hidden_size)\n",
    "decoder = AttnDecoderRNN(y_embeddings, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(EncoderRNN (\n",
       "   (embedding): Embedding(13512, 200)\n",
       "   (lstm): LSTM(200, 200, num_layers=2, batch_first=True)\n",
       " ), AttnDecoderRNN (\n",
       "   (embedding): Embedding(20003, 200)\n",
       "   (new_input): Linear (400 -> 200)\n",
       "   (lstm): LSTM(200, 200, num_layers=2)\n",
       "   (out): Linear (200 -> 20003)\n",
       " ))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly pick sentences from test sets for testing\n",
    "X_ix = [i for i, e in enumerate(X_id_padded_test) if X_word_to_id['UNK'] not in e]\n",
    "y_ix = [i for i, e in enumerate(y_id_padded_test) if y_word_to_id['UNK'] not in e]\n",
    "ix = list(set(X_ix).intersection(y_ix))\n",
    "\n",
    "X_id_padded_test_clean, y_id_padded_test_clean = X_id_padded_test[ix], y_id_padded_test[ix]\n",
    "\n",
    "np.random.seed(123456)\n",
    "np.random.shuffle(ix)\n",
    "ix = ix[:3]\n",
    "\n",
    "X_test = X_id_padded_test_clean[ix]\n",
    "y_test = y_id_padded_test_clean[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Translate test sentences and visualize attention\n",
    "def translate_tests(X_test, y_test):\n",
    "    X_test_var = Variable(torch.from_numpy(X_test).long())\n",
    "    if use_cuda:\n",
    "        X_test_var = X_test_var.cuda()\n",
    "    translations, decoder_attentions = evaluate(X_test_var, encoder, decoder, max_len)\n",
    "    \n",
    "    input_sentences = []\n",
    "    target_sentences = []\n",
    "    output_sentences = []\n",
    "    \n",
    "    for t in range(X_test.shape[0]):\n",
    "        input_sentence = ' '.join([X_id_to_word[ix] for ix in X_test[t] if ix > 0])\n",
    "        target_sentence = ' '.join([y_id_to_word[ix] for ix in y_test[t] if ix > 0])\n",
    "        \n",
    "        # Cut off translations at the first 'ZERO' padding\n",
    "        first_zero_ix = np.where(translations[t] == 0)[0]\n",
    "        if len(first_zero_ix) > 0:\n",
    "            output_sentence = ' '.join([y_id_to_word[ix] for ix in translations[t][:first_zero_ix[0]]])\n",
    "        else:\n",
    "            output_sentence = ' '.join([y_id_to_word[ix] for ix in translations[t]])\n",
    "        \n",
    "        input_sentences.append(input_sentence)\n",
    "        target_sentences.append(target_sentence)\n",
    "        output_sentences.append(output_sentence)\n",
    "        \n",
    "    return input_sentences, target_sentences, output_sentences, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "First sentence in English: she forgot that she had promised to call him last night\n",
      "First sentence in French: elle a oublié qu'elle avait promis de l'appeler la nuit passée\n",
      "\n",
      "Training loss: 2.1489104480784973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Runze/anaconda/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/Runze/anaconda/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translation of i have to dress up : j'ai suis de\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux de\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il a de de de\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 1\n",
      "First sentence in English: you can't do this to us\n",
      "First sentence in French: tu ne peux pas nous faire ça\n",
      "\n",
      "Training loss: 1.8543515450554477\n",
      "\n",
      "Translation of i have to dress up : j'ai me suis\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux aller\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il a fait de qu'il à\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 2\n",
      "First sentence in English: i can't imagine living like that\n",
      "First sentence in French: je ne peux pas imaginer de vivre ainsi\n",
      "\n",
      "Training loss: 1.6750223109924718\n",
      "\n",
      "Translation of i have to dress up : j'ai dois de un\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux aller\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il a toujours de de de\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 3\n",
      "First sentence in English: i hate my computer\n",
      "First sentence in French: je déteste mon ordinateur\n",
      "\n",
      "Training loss: 1.5781759486478906\n",
      "\n",
      "Translation of i have to dress up : je dois faut réparer\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux le rendre\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il a le avec avec avec\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 4\n",
      "First sentence in English: i lost three kilograms\n",
      "First sentence in French: je perdis trois kilos\n",
      "\n",
      "Training loss: 1.482546116531804\n",
      "\n",
      "Translation of i have to dress up : il me faut de\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux le\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il semble tout de le de de\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 5\n",
      "First sentence in English: you gotta get more organized\n",
      "First sentence in French: faut que vous soyez plus organisées\n",
      "\n",
      "Training loss: 1.414174645243127\n",
      "\n",
      "Translation of i have to dress up : je dois faut des\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux le\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit à le avec de la\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 6\n",
      "First sentence in English: i can't run as fast as he can\n",
      "First sentence in French: je ne peux pas courir aussi vite qu'il le peut\n",
      "\n",
      "Training loss: 1.377130418457497\n",
      "\n",
      "Translation of i have to dress up : je dois faut de\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux faire\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit à temps avec le de\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 7\n",
      "First sentence in English: you ran a red light\n",
      "First sentence in French: vous êtes passée au feu rouge\n",
      "\n",
      "Training loss: 1.3278176432341535\n",
      "\n",
      "Translation of i have to dress up : je dois cesser de\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux mourir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle à la de de de\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 8\n",
      "First sentence in English: i want this photograph developed as soon as possible\n",
      "First sentence in French: je veux que cette photo soit développée aussi vite que possible\n",
      "\n",
      "Training loss: 1.2875823037556835\n",
      "\n",
      "Translation of i have to dress up : je dois ouvrir une voiture\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux le\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il travaille à avec avec de à de\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 9\n",
      "First sentence in English: i had to stop\n",
      "First sentence in French: il me fallait arrêter\n",
      "\n",
      "Training loss: 1.2502602552276816\n",
      "\n",
      "Translation of i have to dress up : il me faut réparer\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux apprendre\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il passe à parler de les de de\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 10\n",
      "First sentence in English: you will never be too old to learn\n",
      "First sentence in French: on n'est jamais trop vieux pour apprendre\n",
      "\n",
      "Training loss: 1.2154322962875197\n",
      "\n",
      "Translation of i have to dress up : il me faut renouveler\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux étudier\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il met à ses autres à à à\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 11\n",
      "First sentence in English: i do love you\n",
      "First sentence in French: je t'aime\n",
      "\n",
      "Training loss: 1.1879568663038198\n",
      "\n",
      "Translation of i have to dress up : je dois prendre une\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux le\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il met à des à de à\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 12\n",
      "First sentence in English: i look forward to my birthday\n",
      "First sentence in French: je me réjouis en vue de mon anniversaire\n",
      "\n",
      "Training loss: 1.1444743665474948\n",
      "\n",
      "Translation of i have to dress up : je dois faut traire\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux devenir marier\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il prend tout les monde en monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 13\n",
      "First sentence in English: i still need to talk to you\n",
      "First sentence in French: il me faut encore te parler\n",
      "\n",
      "Training loss: 1.1246840940321707\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux devenir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il met ses parents avec ses monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 14\n",
      "First sentence in English: we should go home\n",
      "First sentence in French: nous devrions rentrer\n",
      "\n",
      "Training loss: 1.0988332562456984\n",
      "\n",
      "Translation of i have to dress up : je dois prendre nouveaux lecture\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il met avec avec ses ses monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 15\n",
      "First sentence in English: i ran into an old friend at tokyo station\n",
      "First sentence in French: j'ai rencontré par hasard un vieil ami à la gare de tokyo\n",
      "\n",
      "Training loss: 1.1381970004578308\n",
      "\n",
      "Translation of i have to dress up : je dois payer payer\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux dormir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle avec avec ses avec ses\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 16\n",
      "First sentence in English: she wiped away her tears\n",
      "First sentence in French: elle essuya ses larmes\n",
      "\n",
      "Training loss: 1.0904613852241207\n",
      "\n",
      "Translation of i have to dress up : je dois prendre une carte\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux aller\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle tout avec à ses monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 17\n",
      "First sentence in English: i hope you know that the last thing i want to do is hurt you\n",
      "First sentence in French: j'espère que vous savez que la dernière chose que je veuille faire est de vous blesser\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.079393038406871\n",
      "\n",
      "Translation of i have to dress up : je dois payer d'avance\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il met courir avec les monde monde monde monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 18\n",
      "First sentence in English: i think i can fix this\n",
      "First sentence in French: je pense que je peux arranger ça\n",
      "\n",
      "Training loss: 1.055570220635607\n",
      "\n",
      "Translation of i have to dress up : je dois acheter de verre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il passe avec avec avec avec ses monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 19\n",
      "First sentence in English: he hurried in order to get the bus\n",
      "First sentence in French: il se hâta pour attraper le bus\n",
      "\n",
      "Training loss: 1.0282297767065713\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il n'arrête à les amis avec le monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 20\n",
      "First sentence in English: you will wish you had never seen it\n",
      "First sentence in French: vous UNK ne l'avoir jamais vu\n",
      "\n",
      "Training loss: 1.0201699088601501\n",
      "\n",
      "Translation of i have to dress up : je dois faut d'avance\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit à paris à monde à monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 21\n",
      "First sentence in English: i put some cookies on the table and the kids ate them right up\n",
      "First sentence in French: j'ai mis quelques biscuits sur la table et les enfants les ont immédiatement UNK\n",
      "\n",
      "Training loss: 1.0002822719108566\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit avec avec les espagnol et son monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 22\n",
      "First sentence in English: i don't need a girlfriend\n",
      "First sentence in French: je n'ai pas besoin de petite copine\n",
      "\n",
      "Training loss: 0.9871200687225614\n",
      "\n",
      "Translation of i have to dress up : je dois me réparer\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il passe à avec le monde de le monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 23\n",
      "First sentence in English: he has the habit of standing up when he is angry\n",
      "First sentence in French: il a l'habitude de se lever lorsqu'il est en colère\n",
      "\n",
      "Training loss: 0.9717608674159497\n",
      "\n",
      "Translation of i have to dress up : je dois me prévenir\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle avec avec les monde et se monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 24\n",
      "First sentence in English: she took him for all his money\n",
      "First sentence in French: elle l'a dépouillé\n",
      "\n",
      "Training loss: 0.9710188496865996\n",
      "\n",
      "Translation of i have to dress up : je dois me concentrer\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me marier\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit parfois avec le monde de se paix\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 25\n",
      "First sentence in English: she may not be aware of the danger\n",
      "First sentence in French: elle n'est peut être pas consciente du danger\n",
      "\n",
      "Training loss: 0.961359272335609\n",
      "\n",
      "Translation of i have to dress up : je dois faut réparer\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit lentement avec avec le monde monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 26\n",
      "First sentence in English: i believe you have my umbrella\n",
      "First sentence in French: je crois que tu as mon parapluie\n",
      "\n",
      "Training loss: 0.9480764822243081\n",
      "\n",
      "Translation of i have to dress up : je dois admettre trente\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle courir avec les monde avec ses monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 27\n",
      "First sentence in English: i need some mental stimulation\n",
      "First sentence in French: j'ai besoin de stimulation mentale\n",
      "\n",
      "Training loss: 0.9346279990958754\n",
      "\n",
      "Translation of i have to dress up : je dois faut réparer\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle parfois avec les avec monde et le monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 28\n",
      "First sentence in English: he is in tokyo\n",
      "First sentence in French: il est à tokyo\n",
      "\n",
      "Training loss: 0.9305386453931886\n",
      "\n",
      "Translation of i have to dress up : je dois acheter acheter\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux parcourir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il trouve tout et tout à à monde monde monde monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 29\n",
      "First sentence in English: i don't feel like singing\n",
      "First sentence in French: je ne suis pas d'humeur à chanter\n",
      "\n",
      "Training loss: 0.9172356957703633\n",
      "\n",
      "Translation of i have to dress up : je dois acheter une\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit parfois et avec tout à en monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 30\n",
      "First sentence in English: i didn't mean to challenge your authority\n",
      "First sentence in French: je ne voulais pas remettre en cause votre autorité\n",
      "\n",
      "Training loss: 0.9265940554001756\n",
      "\n",
      "Translation of i have to dress up : je dois me renouveler\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit parfois et tous à se monde de pied\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 31\n",
      "First sentence in English: i hid under the table\n",
      "First sentence in French: je me cachai sous la table\n",
      "\n",
      "Training loss: 0.9191918145597369\n",
      "\n",
      "Translation of i have to dress up : je dois boire de\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il est tout et temps et se temps se monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 32\n",
      "First sentence in English: we don't want them to decrease our paycheck\n",
      "First sentence in French: nous ne voulons pas qu'ils réduisent notre paie\n",
      "\n",
      "Training loss: 0.9134976311187081\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit près tous tous tous tous de de\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 33\n",
      "First sentence in English: i don't know where it is\n",
      "First sentence in French: je ne sais pas où c'est\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.9041236970938896\n",
      "\n",
      "Translation of i have to dress up : je dois acheter d'acheter\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit moi avec avec les avec les propres\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 34\n",
      "First sentence in English: i have low blood pressure\n",
      "First sentence in French: j'ai une tension basse\n",
      "\n",
      "Training loss: 0.9007305180584946\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit tout tous tous tous tous tous tous\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 35\n",
      "First sentence in English: i just want a vacation\n",
      "First sentence in French: je veux simplement des vacances\n",
      "\n",
      "Training loss: 0.8825015362051845\n",
      "\n",
      "Translation of i have to dress up : je dois faut une\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il s'est et et et et tous à pied\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 36\n",
      "First sentence in English: she took up his offer\n",
      "First sentence in French: elle accepta sa proposition\n",
      "\n",
      "Training loss: 0.8758520344503569\n",
      "\n",
      "Translation of i have to dress up : je dois cesser de\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se tous tous tous tous tous tous monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 37\n",
      "First sentence in English: we have to crack down on illegal trading\n",
      "First sentence in French: il faut prendre des mesures plus fermes contre le commerce illégal\n",
      "\n",
      "Training loss: 0.8562954084026525\n",
      "\n",
      "Translation of i have to dress up : je dois me UNK\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il met à tous tous les monde à le monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 38\n",
      "First sentence in English: he was curious about how it would taste so he took a small bite\n",
      "First sentence in French: il était curieux du goût que ça aurait alors il en mordit un petit morceau\n",
      "\n",
      "Training loss: 0.861143560243328\n",
      "\n",
      "Translation of i have to dress up : je dois faut hier\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle avec les tous tous tous tous tous\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 39\n",
      "First sentence in English: he wouldn't believe us\n",
      "First sentence in French: il a refusé de nous croire\n",
      "\n",
      "Training loss: 0.8689429756862665\n",
      "\n",
      "Translation of i have to dress up : je dois faut une\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il le monde et tout à se monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 40\n",
      "First sentence in English: i don't know what else i can say\n",
      "First sentence in French: je ne sais pas ce que je peux dire d'autre\n",
      "\n",
      "Training loss: 0.8613779403545235\n",
      "\n",
      "Translation of i have to dress up : je dois repasser mon\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir met\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit amies les matins et se monde monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 41\n",
      "First sentence in English: i went to the bank to take out money\n",
      "First sentence in French: je suis allé à la banque pour prendre de l'argent\n",
      "\n",
      "Training loss: 0.8629322283667932\n",
      "\n",
      "Translation of i have to dress up : je dois repasser une\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se général les monde monde monde monde monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 42\n",
      "First sentence in English: i will go to new york next week\n",
      "First sentence in French: j'irai à new york la semaine prochaine\n",
      "\n",
      "Training loss: 0.8562395477087144\n",
      "\n",
      "Translation of i have to dress up : je dois perdre mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle près et se monde s'en se monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 43\n",
      "First sentence in English: i paid in advance\n",
      "First sentence in French: j'ai payé d'avance\n",
      "\n",
      "Training loss: 0.8513122076562288\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se mangeons tous se se monde se revoir\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 44\n",
      "First sentence in English: you have to acquire real skills not just superficial knowledge\n",
      "First sentence in French: il vous faut acquérir de véritables compétences pas juste une connaissance superficielle\n",
      "\n",
      "Training loss: 0.8412653525150938\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se parfois avec tous tous tous se monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 45\n",
      "First sentence in English: you fainted\n",
      "First sentence in French: vous vous êtes évanouie\n",
      "\n",
      "Training loss: 0.8332117433901183\n",
      "\n",
      "Translation of i have to dress up : je dois nourrir traire\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il vit à elles à pied à se revoir\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 46\n",
      "First sentence in English: he betrayed you\n",
      "First sentence in French: il vous a trahie\n",
      "\n",
      "Training loss: 0.8349948421802392\n",
      "\n",
      "Translation of i have to dress up : je dois faut de boire\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se met à se monde à se monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 47\n",
      "First sentence in English: i want to know what you're doing here\n",
      "First sentence in French: je veux savoir ce que vous fichez là\n",
      "\n",
      "Training loss: 0.845420893085288\n",
      "\n",
      "Translation of i have to dress up : je dois acheter boire\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se parle tous tous tous tous tous\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 48\n",
      "First sentence in English: we have not heard from him since last year\n",
      "First sentence in French: nous n'avons pas eu de nouvelles de lui depuis l'année dernière\n",
      "\n",
      "Training loss: 0.8481271935963682\n",
      "\n",
      "Translation of i have to dress up : je dois me UNK\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux me\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il le et et et se monde se\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 49\n",
      "First sentence in English: i don't want to go back to prison\n",
      "First sentence in French: je ne veux pas retourner en prison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.8522056194172442\n",
      "\n",
      "Translation of i have to dress up : je dois faut mon protestation\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il le à tous tout se monde se monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 50\n",
      "First sentence in English: you can't count on him for financial help\n",
      "First sentence in French: tu ne peux pas compter sur son aide financière\n",
      "\n",
      "Training loss: 0.8351935019939816\n",
      "\n",
      "Translation of i have to dress up : je dois repasser après\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se près tous lui tout tout le monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 51\n",
      "First sentence in English: i need you to do me a favor\n",
      "First sentence in French: j'ai besoin que tu me rendes un service\n",
      "\n",
      "Training loss: 0.8418487004465007\n",
      "\n",
      "Translation of i have to dress up : je dois en mon\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux en\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il est à lui lui le tout à lui\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 52\n",
      "First sentence in English: he has just published an interesting series of articles\n",
      "First sentence in French: il vient de publier une série intéressante d’articles\n",
      "\n",
      "Training loss: 0.8458012011575802\n",
      "\n",
      "Translation of i have to dress up : je dois faut une\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il est à avec avec de de les autres\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 53\n",
      "First sentence in English: she likes these cats\n",
      "First sentence in French: elle aime bien ces chats\n",
      "\n",
      "Training loss: 0.8311825581885129\n",
      "\n",
      "Translation of i have to dress up : je dois mettre trente\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il parle à tout à se monde tous\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 54\n",
      "First sentence in English: she turned off the lights\n",
      "First sentence in French: elle éteignit les lumières\n",
      "\n",
      "Training loss: 0.8184880160038764\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre mon nouveau\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se français avec elle se se monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 55\n",
      "First sentence in English: i have no idea what that guy is thinking\n",
      "First sentence in French: je n'ai aucune idée de ce que pense ce type\n",
      "\n",
      "Training loss: 0.8136535047186226\n",
      "\n",
      "Translation of i have to dress up : je dois t'enseigner mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se à la pied à le chemin de revoir\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 56\n",
      "First sentence in English: i knew you were behind it\n",
      "First sentence in French: je savais que vous étiez derrière\n",
      "\n",
      "Training loss: 0.810304765659739\n",
      "\n",
      "Translation of i have to dress up : je dois me verre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il continue à la à la la temps la soleil\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 57\n",
      "First sentence in English: he came in through the window\n",
      "First sentence in French: il est entré par la fenêtre\n",
      "\n",
      "Training loss: 0.8197453949705968\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il travaille à à aller et la sont de bois\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 58\n",
      "First sentence in English: i don't know how to reply to that question\n",
      "First sentence in French: je ne sais comment répondre à cette question\n",
      "\n",
      "Training loss: 0.8119359907761117\n",
      "\n",
      "Translation of i have to dress up : je dois prévenir de\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il se amis à les courses avec sont monde monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n",
      "Epoch: 59\n",
      "First sentence in English: i know you don't like me\n",
      "First sentence in French: je sais que tu ne m'aimes pas\n",
      "\n",
      "Training loss: 0.8119185514179964\n",
      "\n",
      "Translation of i have to dress up : je dois me mettre\n",
      "Actual translation: je dois me faire beau\n",
      "\n",
      "Translation of i want to run : je veux courir\n",
      "Actual translation: je veux courir\n",
      "\n",
      "Translation of he makes friends with everybody he meets : il est travaille à aller à la monde de monde\n",
      "Actual translation: il se lie d'amitié avec tous ceux qu'il rencontre\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print('Epoch:', i)\n",
    "    \n",
    "    # Shuffle the training data every epoch to avoid local minima\n",
    "    np.random.seed(i)\n",
    "    ix = np.arange(len(X_id_padded_train))\n",
    "    np.random.shuffle(ix)\n",
    "    \n",
    "    X_id_padded_train, y_id_padded_train = X_id_padded_train[ix], y_id_padded_train[ix]\n",
    "    \n",
    "    # Print out the first sentence in X and y for sanity check\n",
    "    print('First sentence in English:', ' '.join([X_id_to_word[ix] for ix in X_id_padded_train[0] if ix > 0]))\n",
    "    print('First sentence in French:', ' '.join([y_id_to_word[ix] for ix in y_id_padded_train[0] if ix > 0]))    \n",
    "    \n",
    "    # Train an epoch    \n",
    "    train_loss = train_epoch(X_id_padded_train, y_id_padded_train, batch_size,\n",
    "                             encoder, decoder, learning_rate, teacher_forcing_prob)\n",
    "    \n",
    "    print('\\nTraining loss:', train_loss)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    torch.save(encoder, 'output/encoder_' + str(i))\n",
    "    torch.save(decoder, 'output/decoder_' + str(i))\n",
    "    \n",
    "    # Evaluate\n",
    "    # Translate test sentences\n",
    "    input_sentences, target_sentences, output_sentences, decoder_attentions = translate_tests(X_test, y_test)\n",
    "    \n",
    "    for j in range(len(input_sentences)):\n",
    "        print('\\nTranslation of', input_sentences[j], ':', output_sentences[j])\n",
    "        print('Actual translation:', target_sentences[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the test data, for each input sentence length, randomly selects 5 sentences\n",
    "X_id_padded_test_sent_len = np.count_nonzero(X_id_padded_test_clean, axis=1)\n",
    "\n",
    "for i in range(min(X_id_padded_test_sent_len), max(X_id_padded_test_sent_len) + 1):\n",
    "    ix = np.where(X_id_padded_test_sent_len == i)[0]\n",
    "    \n",
    "    np.random.seed(123456)\n",
    "    np.random.shuffle(ix)\n",
    "    ix = ix[:5]\n",
    "    \n",
    "    if i == min(X_id_padded_test_sent_len):\n",
    "        X_test = X_id_padded_test_clean[ix]\n",
    "        y_test = y_id_padded_test_clean[ix]\n",
    "    else:\n",
    "        X_test = np.append(X_test, X_id_padded_test_clean[ix], axis=0)\n",
    "        y_test = np.append(y_test, y_id_padded_test_clean[ix], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate translations\n",
    "input_sentences, target_sentences, output_sentences, decoder_attentions = translate_tests(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_sentence</th>\n",
       "      <th>model_translation</th>\n",
       "      <th>ground_truth_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i disagree</td>\n",
       "      <td>je ne suis pas d’accord</td>\n",
       "      <td>je ne suis pas d'accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we try</td>\n",
       "      <td>nous travaillons nouveau</td>\n",
       "      <td>on essaye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i refuse</td>\n",
       "      <td>je suis refuse</td>\n",
       "      <td>je refuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i promised</td>\n",
       "      <td>je m'en promis</td>\n",
       "      <td>j'ai promis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you cheated</td>\n",
       "      <td>vous as triché</td>\n",
       "      <td>tu as triché</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>we need water</td>\n",
       "      <td>nous avons faut d'eau</td>\n",
       "      <td>il nous faut de l'eau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>she is kind</td>\n",
       "      <td>elle est gentille</td>\n",
       "      <td>elle est gentille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we shared everything</td>\n",
       "      <td>nous avons tout tout</td>\n",
       "      <td>nous avons tout partagé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i totally forgot</td>\n",
       "      <td>je déteste oublié</td>\n",
       "      <td>j'ai complètement oublié</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i felt awful</td>\n",
       "      <td>je me sentais senti senti affreusement</td>\n",
       "      <td>je me suis sentie affreusement mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i was really upset</td>\n",
       "      <td>j'étais vraiment curieux</td>\n",
       "      <td>j'étais vraiment triste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>he is no fool</td>\n",
       "      <td>il n'est pas fou</td>\n",
       "      <td>il n'est pas idiot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>he drives me crazy</td>\n",
       "      <td>il me rend fou</td>\n",
       "      <td>il me rend dingue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i hurt myself today</td>\n",
       "      <td>je me suis bien aujourd'hui aujourd'hui aujour...</td>\n",
       "      <td>je me suis fait mal aujourd'hui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i learned something today</td>\n",
       "      <td>j'ai fait quelque chose aujourd'hui aujourd'hui</td>\n",
       "      <td>j'ai appris quelque chose aujourd'hui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>you have to keep fit</td>\n",
       "      <td>vous devez garder la forme</td>\n",
       "      <td>vous devez garder la forme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>he lives within his means</td>\n",
       "      <td>il vit son son</td>\n",
       "      <td>il vit selon ses moyens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>she seems to be sick</td>\n",
       "      <td>elle semble être malade malade</td>\n",
       "      <td>elle a l'air d'être malade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>she talked to the chairperson</td>\n",
       "      <td>elle a parlé de invités invités</td>\n",
       "      <td>elle a parlé avec le président</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you only need to concentrate</td>\n",
       "      <td>il se suffit que vous veuilles demander</td>\n",
       "      <td>vous devez seulement vous concentrer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>i don't understand why you're leaving</td>\n",
       "      <td>je ne comprends pas pourquoi tu vas</td>\n",
       "      <td>je ne comprends pas pourquoi tu pars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>i will never forget seeing you</td>\n",
       "      <td>je n'oublierai jamais t'avoir rencontrer</td>\n",
       "      <td>je n'oublierai jamais vous avoir vus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>he couldn't concentrate on the conversation</td>\n",
       "      <td>il pourrait put me de succès la moral</td>\n",
       "      <td>il ne pouvait se concentrer sur la conversation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>i loved working here with you</td>\n",
       "      <td>j'ai adoré travailler travailler toi</td>\n",
       "      <td>j'ai adoré travailler ici avec vous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>i can't believe he kissed you</td>\n",
       "      <td>je n'arrive pas à croire qu'il qu'il ait embra...</td>\n",
       "      <td>je ne parviens pas à croire qu'il vous ait emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>he turned out to be her father</td>\n",
       "      <td>il a tourné son père</td>\n",
       "      <td>il se révéla être son père</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>i only found out about that today</td>\n",
       "      <td>je ne l'ai écrit à ce rapport</td>\n",
       "      <td>je ne l'ai découvert qu'aujourd'hui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i want you to take this medicine</td>\n",
       "      <td>je veux que tu ayez cette médicament</td>\n",
       "      <td>je veux que vous preniez ce médicament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>we shared the profit among us all</td>\n",
       "      <td>nous avons d'autres les raisons pont pont à</td>\n",
       "      <td>nous partageâmes les profits entre nous tous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>i didn't want you involved in this</td>\n",
       "      <td>je ne voulais pas que vous soyez impliqué à ça</td>\n",
       "      <td>je ne voulais pas que tu sois mêlé à ça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>i just know that i don't want to be married to...</td>\n",
       "      <td>je sais tout simplement que je ne veux pas mar...</td>\n",
       "      <td>je sais que je ne veux pas être mariée avec vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>i was surprised because my husband actually at...</td>\n",
       "      <td>j'ai été surprise par j'ai professeur grand gr...</td>\n",
       "      <td>j'étais surprise parce que mon mari avait en f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>i have made up my mind to achieve my goals in ...</td>\n",
       "      <td>je me doutes à l'université l'université trois...</td>\n",
       "      <td>je me suis décidé à atteindre mes objectifs da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>he is sure to pass the exam if he studies at t...</td>\n",
       "      <td>il est sûr qu'il le puisse qu'il qu'il le le l...</td>\n",
       "      <td>il est certain de réussir l'examen s'il étudie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>she looked after her sister who was in bed wit...</td>\n",
       "      <td>elle regarda auprès au garçon faisait le garço...</td>\n",
       "      <td>elle s'est occupée de sa sœur qui était alitée...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>i knew we were going to get married the moment...</td>\n",
       "      <td>je savais que nous allions nous marier à je mo...</td>\n",
       "      <td>je savais que nous allions nous marier au mome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>we will have to put off the soccer game becaus...</td>\n",
       "      <td>il aurait de le fac du du soleil du soleil du ...</td>\n",
       "      <td>nous allons devoir reporter le match de foot à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>i think it's time for me to spend a little tim...</td>\n",
       "      <td>je pense qu'il est temps que je vais à essayer...</td>\n",
       "      <td>je pense qu'il est temps que je passe un peu d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>he had been living in nagano for seven years w...</td>\n",
       "      <td>il vivait quand quand quand depuis depuis étai...</td>\n",
       "      <td>il vivait à nagano depuis sept ans quand sa sœ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>i want to give you some money to help you thro...</td>\n",
       "      <td>je veux te donner quelques l'argent pour t'aid...</td>\n",
       "      <td>je veux vous donner de l'argent pour vous aide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>i can't show up looking like i've been working...</td>\n",
       "      <td>je ne parviens pas trouver comment oublié de l...</td>\n",
       "      <td>je ne peux pas me montrer avec l'air de quelqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>i do not have the courage to ask my boss to le...</td>\n",
       "      <td>je pense que la numéro de la que je père de tr...</td>\n",
       "      <td>je n'ai pas le courage de demander à mon patro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>i like this picture not because it is a master...</td>\n",
       "      <td>j'aime ce groupe qui est pas pas parce parce p...</td>\n",
       "      <td>j'aime cette peinture non pas parce que c'est ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>i know how to solve the problem but i've been ...</td>\n",
       "      <td>je sais comment résoudre comment l'argent mais...</td>\n",
       "      <td>je sais comment résoudre le problème mais on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>he decided to feed his dog the rabbit that he ...</td>\n",
       "      <td>il a décidé de se père à la père qu'il il étai...</td>\n",
       "      <td>il décida de donner à manger à son chien le la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>she advised him to go there alone but he didn'...</td>\n",
       "      <td>elle lui a recommandé de faire mais mais ne ne...</td>\n",
       "      <td>elle lui recommanda d'y aller seul mais il ne ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>i can't believe that you aren't at least willi...</td>\n",
       "      <td>je n'arrive pas à croire que vous ne soyez pas...</td>\n",
       "      <td>je n'arrive pas à croire que vous ne soyez pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>i got it through my head that my parent's stri...</td>\n",
       "      <td>je l'ai suis par perdu perdu perdu pour la la ...</td>\n",
       "      <td>je me suis convaincu que les règles strictes d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>she got so carried away listening to the beatl...</td>\n",
       "      <td>elle a réussi réussi qu'il qu'il qu'il qu'il a...</td>\n",
       "      <td>elle écoutait les beatles et s'est tellement l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>i had a few hours free so i sat under a tree a...</td>\n",
       "      <td>j'avais déjeuné du lit alors coucher que je qu...</td>\n",
       "      <td>je disposai de quelques heures de libres aussi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>he is usually straightforward and sincere and ...</td>\n",
       "      <td>il est arrivé et son son qu'il le le le le le ...</td>\n",
       "      <td>il est d'ordinaire direct et sincère et gagne ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>i don't think that there is any better way to ...</td>\n",
       "      <td>je ne pense pas qu'il parle français japonais ...</td>\n",
       "      <td>je ne pense pas qu'il y ait de meilleure métho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>i know you've been waiting a long time but cou...</td>\n",
       "      <td>je sais que tu as le fois plus plus que tu foi...</td>\n",
       "      <td>je sais que vous avez attendu pendant longtemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>you may not agree with him but at least he sta...</td>\n",
       "      <td>il n'es peut pour lui lui lui pour lui pour lu...</td>\n",
       "      <td>peut être n'êtes vous pas d'accord avec lui ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>i suggest you have a native speaker read over ...</td>\n",
       "      <td>je suggère que tu ailles apprécier de plus mai...</td>\n",
       "      <td>je suggère que tu fasses relire ton rapport pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>she asked him to give her some money so she co...</td>\n",
       "      <td>elle lui a de lui lui lui ses le lui lui lui l...</td>\n",
       "      <td>elle lui a demandé de lui donner de l'argent p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>i guess what i've said isn't all that clear bu...</td>\n",
       "      <td>j'imagine que que ce que ce ne ne décidé pas p...</td>\n",
       "      <td>je devine que ce que j'ai dit n'est pas très c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>i began driving our tractor when i was 12 year...</td>\n",
       "      <td>j'avais à la garde quand notre père quand je p...</td>\n",
       "      <td>je conduisais notre tracteur dès l'âge de 12 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>you may not be in the mood to hear this now bu...</td>\n",
       "      <td>tu se quant s'occuper que tu ne ne ce que ce q...</td>\n",
       "      <td>peut être n'es tu pas d'humeur à entendre ça m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>he is likely to have a book and a cracker at h...</td>\n",
       "      <td>le amitié le train ans mari lit lit lit lit li...</td>\n",
       "      <td>il a des chances d'avoir un livre et un biscui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       input_sentence  \\\n",
       "0                                          i disagree   \n",
       "1                                              we try   \n",
       "2                                            i refuse   \n",
       "3                                          i promised   \n",
       "4                                         you cheated   \n",
       "5                                       we need water   \n",
       "6                                         she is kind   \n",
       "7                                we shared everything   \n",
       "8                                    i totally forgot   \n",
       "9                                        i felt awful   \n",
       "10                                 i was really upset   \n",
       "11                                      he is no fool   \n",
       "12                                 he drives me crazy   \n",
       "13                                i hurt myself today   \n",
       "14                          i learned something today   \n",
       "15                               you have to keep fit   \n",
       "16                          he lives within his means   \n",
       "17                               she seems to be sick   \n",
       "18                      she talked to the chairperson   \n",
       "19                       you only need to concentrate   \n",
       "20              i don't understand why you're leaving   \n",
       "21                     i will never forget seeing you   \n",
       "22        he couldn't concentrate on the conversation   \n",
       "23                      i loved working here with you   \n",
       "24                      i can't believe he kissed you   \n",
       "25                     he turned out to be her father   \n",
       "26                  i only found out about that today   \n",
       "27                   i want you to take this medicine   \n",
       "28                  we shared the profit among us all   \n",
       "29                 i didn't want you involved in this   \n",
       "..                                                ...   \n",
       "54  i just know that i don't want to be married to...   \n",
       "55  i was surprised because my husband actually at...   \n",
       "56  i have made up my mind to achieve my goals in ...   \n",
       "57  he is sure to pass the exam if he studies at t...   \n",
       "58  she looked after her sister who was in bed wit...   \n",
       "59  i knew we were going to get married the moment...   \n",
       "60  we will have to put off the soccer game becaus...   \n",
       "61  i think it's time for me to spend a little tim...   \n",
       "62  he had been living in nagano for seven years w...   \n",
       "63  i want to give you some money to help you thro...   \n",
       "64  i can't show up looking like i've been working...   \n",
       "65  i do not have the courage to ask my boss to le...   \n",
       "66  i like this picture not because it is a master...   \n",
       "67  i know how to solve the problem but i've been ...   \n",
       "68  he decided to feed his dog the rabbit that he ...   \n",
       "69  she advised him to go there alone but he didn'...   \n",
       "70  i can't believe that you aren't at least willi...   \n",
       "71  i got it through my head that my parent's stri...   \n",
       "72  she got so carried away listening to the beatl...   \n",
       "73  i had a few hours free so i sat under a tree a...   \n",
       "74  he is usually straightforward and sincere and ...   \n",
       "75  i don't think that there is any better way to ...   \n",
       "76  i know you've been waiting a long time but cou...   \n",
       "77  you may not agree with him but at least he sta...   \n",
       "78  i suggest you have a native speaker read over ...   \n",
       "79  she asked him to give her some money so she co...   \n",
       "80  i guess what i've said isn't all that clear bu...   \n",
       "81  i began driving our tractor when i was 12 year...   \n",
       "82  you may not be in the mood to hear this now bu...   \n",
       "83  he is likely to have a book and a cracker at h...   \n",
       "\n",
       "                                    model_translation  \\\n",
       "0                             je ne suis pas d’accord   \n",
       "1                            nous travaillons nouveau   \n",
       "2                                      je suis refuse   \n",
       "3                                      je m'en promis   \n",
       "4                                      vous as triché   \n",
       "5                               nous avons faut d'eau   \n",
       "6                                   elle est gentille   \n",
       "7                                nous avons tout tout   \n",
       "8                                   je déteste oublié   \n",
       "9              je me sentais senti senti affreusement   \n",
       "10                           j'étais vraiment curieux   \n",
       "11                                   il n'est pas fou   \n",
       "12                                     il me rend fou   \n",
       "13  je me suis bien aujourd'hui aujourd'hui aujour...   \n",
       "14    j'ai fait quelque chose aujourd'hui aujourd'hui   \n",
       "15                         vous devez garder la forme   \n",
       "16                                     il vit son son   \n",
       "17                     elle semble être malade malade   \n",
       "18                    elle a parlé de invités invités   \n",
       "19            il se suffit que vous veuilles demander   \n",
       "20                je ne comprends pas pourquoi tu vas   \n",
       "21           je n'oublierai jamais t'avoir rencontrer   \n",
       "22              il pourrait put me de succès la moral   \n",
       "23               j'ai adoré travailler travailler toi   \n",
       "24  je n'arrive pas à croire qu'il qu'il ait embra...   \n",
       "25                               il a tourné son père   \n",
       "26                      je ne l'ai écrit à ce rapport   \n",
       "27               je veux que tu ayez cette médicament   \n",
       "28        nous avons d'autres les raisons pont pont à   \n",
       "29     je ne voulais pas que vous soyez impliqué à ça   \n",
       "..                                                ...   \n",
       "54  je sais tout simplement que je ne veux pas mar...   \n",
       "55  j'ai été surprise par j'ai professeur grand gr...   \n",
       "56  je me doutes à l'université l'université trois...   \n",
       "57  il est sûr qu'il le puisse qu'il qu'il le le l...   \n",
       "58  elle regarda auprès au garçon faisait le garço...   \n",
       "59  je savais que nous allions nous marier à je mo...   \n",
       "60  il aurait de le fac du du soleil du soleil du ...   \n",
       "61  je pense qu'il est temps que je vais à essayer...   \n",
       "62  il vivait quand quand quand depuis depuis étai...   \n",
       "63  je veux te donner quelques l'argent pour t'aid...   \n",
       "64  je ne parviens pas trouver comment oublié de l...   \n",
       "65  je pense que la numéro de la que je père de tr...   \n",
       "66  j'aime ce groupe qui est pas pas parce parce p...   \n",
       "67  je sais comment résoudre comment l'argent mais...   \n",
       "68  il a décidé de se père à la père qu'il il étai...   \n",
       "69  elle lui a recommandé de faire mais mais ne ne...   \n",
       "70  je n'arrive pas à croire que vous ne soyez pas...   \n",
       "71  je l'ai suis par perdu perdu perdu pour la la ...   \n",
       "72  elle a réussi réussi qu'il qu'il qu'il qu'il a...   \n",
       "73  j'avais déjeuné du lit alors coucher que je qu...   \n",
       "74  il est arrivé et son son qu'il le le le le le ...   \n",
       "75  je ne pense pas qu'il parle français japonais ...   \n",
       "76  je sais que tu as le fois plus plus que tu foi...   \n",
       "77  il n'es peut pour lui lui lui pour lui pour lu...   \n",
       "78  je suggère que tu ailles apprécier de plus mai...   \n",
       "79  elle lui a de lui lui lui ses le lui lui lui l...   \n",
       "80  j'imagine que que ce que ce ne ne décidé pas p...   \n",
       "81  j'avais à la garde quand notre père quand je p...   \n",
       "82  tu se quant s'occuper que tu ne ne ce que ce q...   \n",
       "83  le amitié le train ans mari lit lit lit lit li...   \n",
       "\n",
       "                             ground_truth_translation  \n",
       "0                             je ne suis pas d'accord  \n",
       "1                                           on essaye  \n",
       "2                                           je refuse  \n",
       "3                                         j'ai promis  \n",
       "4                                        tu as triché  \n",
       "5                               il nous faut de l'eau  \n",
       "6                                   elle est gentille  \n",
       "7                             nous avons tout partagé  \n",
       "8                            j'ai complètement oublié  \n",
       "9                  je me suis sentie affreusement mal  \n",
       "10                            j'étais vraiment triste  \n",
       "11                                 il n'est pas idiot  \n",
       "12                                  il me rend dingue  \n",
       "13                    je me suis fait mal aujourd'hui  \n",
       "14              j'ai appris quelque chose aujourd'hui  \n",
       "15                         vous devez garder la forme  \n",
       "16                            il vit selon ses moyens  \n",
       "17                         elle a l'air d'être malade  \n",
       "18                     elle a parlé avec le président  \n",
       "19               vous devez seulement vous concentrer  \n",
       "20               je ne comprends pas pourquoi tu pars  \n",
       "21               je n'oublierai jamais vous avoir vus  \n",
       "22    il ne pouvait se concentrer sur la conversation  \n",
       "23                j'ai adoré travailler ici avec vous  \n",
       "24  je ne parviens pas à croire qu'il vous ait emb...  \n",
       "25                         il se révéla être son père  \n",
       "26                je ne l'ai découvert qu'aujourd'hui  \n",
       "27             je veux que vous preniez ce médicament  \n",
       "28       nous partageâmes les profits entre nous tous  \n",
       "29            je ne voulais pas que tu sois mêlé à ça  \n",
       "..                                                ...  \n",
       "54  je sais que je ne veux pas être mariée avec vo...  \n",
       "55  j'étais surprise parce que mon mari avait en f...  \n",
       "56  je me suis décidé à atteindre mes objectifs da...  \n",
       "57  il est certain de réussir l'examen s'il étudie...  \n",
       "58  elle s'est occupée de sa sœur qui était alitée...  \n",
       "59  je savais que nous allions nous marier au mome...  \n",
       "60  nous allons devoir reporter le match de foot à...  \n",
       "61  je pense qu'il est temps que je passe un peu d...  \n",
       "62  il vivait à nagano depuis sept ans quand sa sœ...  \n",
       "63  je veux vous donner de l'argent pour vous aide...  \n",
       "64  je ne peux pas me montrer avec l'air de quelqu...  \n",
       "65  je n'ai pas le courage de demander à mon patro...  \n",
       "66  j'aime cette peinture non pas parce que c'est ...  \n",
       "67  je sais comment résoudre le problème mais on m...  \n",
       "68  il décida de donner à manger à son chien le la...  \n",
       "69  elle lui recommanda d'y aller seul mais il ne ...  \n",
       "70  je n'arrive pas à croire que vous ne soyez pas...  \n",
       "71  je me suis convaincu que les règles strictes d...  \n",
       "72  elle écoutait les beatles et s'est tellement l...  \n",
       "73  je disposai de quelques heures de libres aussi...  \n",
       "74  il est d'ordinaire direct et sincère et gagne ...  \n",
       "75  je ne pense pas qu'il y ait de meilleure métho...  \n",
       "76  je sais que vous avez attendu pendant longtemp...  \n",
       "77  peut être n'êtes vous pas d'accord avec lui ma...  \n",
       "78  je suggère que tu fasses relire ton rapport pa...  \n",
       "79  elle lui a demandé de lui donner de l'argent p...  \n",
       "80  je devine que ce que j'ai dit n'est pas très c...  \n",
       "81  je conduisais notre tracteur dès l'âge de 12 a...  \n",
       "82  peut être n'es tu pas d'humeur à entendre ça m...  \n",
       "83  il a des chances d'avoir un livre et un biscui...  \n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_translations = pd.DataFrame({\n",
    "    'input_sentence': input_sentences,\n",
    "    'ground_truth_translation': target_sentences,\n",
    "    'model_translation': output_sentences\n",
    "})\n",
    "\n",
    "test_translations = test_translations[['input_sentence', 'model_translation', 'ground_truth_translation']]\n",
    "test_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_translations.to_clipboard()\n",
    "test_translations.to_csv('output/test_translations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
